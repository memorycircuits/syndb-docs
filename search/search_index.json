{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"troubleshoot/","title":"Troubleshooting","text":"<p>Find up-to date explanations of different types of errors, and pointers on how to resolve them.</p>"},{"location":"troubleshoot/#403-unauthorized","title":"403, Unauthorized","text":""},{"location":"troubleshoot/#verification","title":"Verification","text":"<p>Academic verification is required for computationally or network heavy tasks. This is to ensure that the resources are not being misused. You may verify yourself after registering on the platform using the CLI or the GUI.</p>"},{"location":"troubleshoot/#dataset","title":"Dataset","text":"<p>A dataset belongs to the creator, and groups that the creator chooses to share its ownership. If you are unable to access a dataset, you fit neither of these categories. You may request access to the dataset from the creator.</p>"},{"location":"dataset/0-overview/","title":"Overview","text":"<p>The SynDB data platform is accessible through the API. By search, you may find and download high level metrics; by upload, you may share your data to become part of a meta-analytical study.</p>"},{"location":"dataset/0-overview/#composition","title":"Composition","text":"<p>The SynDB data platform is designed to provide a comprehensive and organized repository of high-resolution microscopy data and associated metadata. The composition of SynDB can be broken down into three main components: Metadata, Image Metrics, and Raw Data. Each of these components plays a crucial role in the functionality and utility of the platform.</p>"},{"location":"dataset/0-overview/#metadata","title":"Metadata","text":"<p>The metadata is used to define and retrieve datasets. It stores metadata about the data in the respective dataset:</p> <ul> <li>Brain region</li> <li>Sourcing model animal</li> <li>Genetic manipulations (mutations)</li> <li>Microscopy method</li> <li>Publication information</li> </ul> <p>The metadata is defined by the data owner during upload.</p> <p>Dataset</p> <p>You must split your dataset into individual SynDB datasets if any of these fields differ within your own dataset.</p>"},{"location":"dataset/0-overview/#image-metrics","title":"Image metrics","text":"<p>The image metrics in SynDB are derived from high-resolution microscopy assays, processed using sophisticated algorithms and models. These metrics form the primary data of interest within the platform. Each neuronal compartment and structure has its own unique set of metric categories, which necessitates distinct database schemas. We will refer to these phenomena as SynDB tables in future references.</p> <p>To facilitate efficient data management, every imaging metric is linked to a dataset via its ID. This linkage enables robust search capabilities by filtering through metadata, thus avoiding the need to handle terabytes of raw data directly. You can learn more about how dataset metadata filtration works in the article on search.</p> <p>The flexible data model of SynDB supports this functionality by defining specific parameters for each compartment and structure. These varied models are unified into comprehensive datasets through dataset metadata, which effectively organizes data groups across the platform. This unified approach ensures that users can efficiently access and analyze the vast array of imaging metrics available in SynDB.</p>"},{"location":"dataset/0-overview/#raw-data","title":"Raw data","text":"<p>Raw data is the original data from which the metrics are derived. The raw data is stored in the database and can be requested from its metric counterpart. Raw data sets currently include meshes and SWC files. These are included at the discretion of the data owner.</p>"},{"location":"dataset/1-search/","title":"Search","text":"<p>The search feature filters through datasets based on the search terms provided by the user. The search terms can be combined to narrow down the search results.</p> <p>By default, every search field is AND meaning that the every term has to exist for in the resulting dataset.</p> <p>TODO</p> <p>Add capabilities to customize the logical operators in the search, e.g., AND, OR, NOT.</p>"},{"location":"dataset/1-search/#download-the-search-results","title":"Download the search results","text":"<p>Following the search, you may download the imaging derived metrics of the datasets from the search results. You will get a single <code>.tar.xz</code> file with parquet files inside. You may read parquet files using the {{ pandas_read_parquet }} or {{ polars_read_parquet }} library in Python.</p> <p>Other languages</p> <p>Apache parquet is a file format supported by most popular programming languages. You may find libraries for reading parquet files in your preferred language.</p>"},{"location":"dataset/2-upload/","title":"Upload","text":"<p>Prerequisites</p> <p>This article requires that you understand how data is stored on SynDB, we recommend reading through the overview article if you are uncertain.</p> <p>Uploading to SynDB is a multistep process, and requires understanding of the SynDB dataset model.</p>"},{"location":"dataset/2-upload/#the-process","title":"The process","text":""},{"location":"dataset/2-upload/#preparation","title":"Preparation","text":"<p>We recommend you to follow the guide in the exact sequence provided. This ensures the instructions are followed effectively and idiomatically.</p>"},{"location":"dataset/2-upload/#terms-and-conditions","title":"Terms and conditions","text":"<p>You must accept the terms and conditions before uploading data. The terms include: - Statement that the data is not false or misleading - Redistribution rights - Data licensing agreement with the license of your choice, see guide to pick license; the default license is ODC-BY.</p>"},{"location":"dataset/2-upload/#data-structuring","title":"Data structuring","text":"<p>SynDB utilizes data standardization to facilitate uploads. Your imaging metrics must be in a tabular data format; for instance, <code>.xlsx</code>, <code>.csv</code>, or <code>.parquet</code>. Read more about the data structuring in the contributor's guide.</p>"},{"location":"dataset/2-upload/#login","title":"Login","text":"<p>Once you enter the upload page, you will be prompted to log in to your SynDB account if you are not already; furthermore, you must verify your academic status by logging in to your institution's account.</p>"},{"location":"dataset/2-upload/#the-upload","title":"The upload","text":"<p>You can upload data using the CLI or the GUI; including mixing the usage of both. We recommend that you only use the GUI for the first time.</p>"},{"location":"dataset/2-upload/#1-assign-ids-and-correlate-relations","title":"1. Assign IDs, and correlate relations","text":"<p>Each SynDB unit requires a unique ID assigned before being uploaded to the platform. The GUI does this automatically, but not the CLI. When you have multiple SynDB tables under one dataset it is expected that these have some relations with each other.</p> <p>Dataset integrity</p> <p>As it may lead to undefined behaviour, it is disallowed to upload SynDB table data that are unrelated under the same dataset!</p> <p>Meaning that you cannot upload a table of neurons and a table of synapses under the same dataset unless each synapse has a relation to a neuron from the respective table of neurons.</p>"},{"location":"dataset/2-upload/#gui","title":"GUI","text":"<p>The GUI will automatically assign UUIDs to each SynDB unit. The relations are correlated based on the top-down hierarchy of the tables, you may find the latest version of the hierarchy in the source on GitHub.</p>"},{"location":"dataset/2-upload/#cli","title":"CLI","text":"<p>TODO</p>"},{"location":"dataset/2-upload/#2-selecting-or-creating-the-syndb-dataset-metadata","title":"2. Selecting or creating the SynDB dataset metadata","text":"<p>As mentioned, in the overview article, every dataset has a metadata defined by the data owner during the upload. You can either select an existing dataset or create a new one.</p>"},{"location":"dataset/2-upload/#3-confirm-and-upload","title":"3. Confirm and upload","text":"<p>Before the upload starts you will be prompted to confirm the dataset and the data you are uploading. Once you confirm, the upload will start. Should be relatively quick.</p>"},{"location":"dataset/2-upload/#delete-owned-datasets","title":"Delete owned datasets","text":"<p>You may at any time delete datasets that you own. This will remove the dataset and all the data associated with it. The deletion is permanent and cannot be undone.</p>"},{"location":"dataset/3-external/","title":"External sources","text":"<p>SynDB support migrating data from other platforms to varying degrees.</p>"},{"location":"dataset/3-external/#cave","title":"CAVE","text":"<p>Only <code>valid_synapses_nt_np</code> datasets from CAVE are supported.</p> <p>Initialize cave first: <pre><code>syndb plugin cave init\n</code></pre></p> <p>Upload to your dataset: <pre><code>syndb plugin cave init transfer --dataset-id &lt;syndb-dataset_id&gt; --cave-datastack-name &lt;cave-datastack-name&gt;\n</code></pre></p> <p>Dataset</p> <p>The <code>syndb-dataset_id</code> is the UUID of the SynDB dataset that will be associated with the CAVE data. You can either press <code>tab</code> to autocomplete the dataset ID, <code>syndb plugin cave init transfer --dataset-id&lt;press TAB here&gt;</code>, or copy and paste from the dataset management page on the GUI.</p>"},{"location":"get_started/0-home/","title":"Welcome to SynDB","text":"<p>SynDB is the platform for finding, and sharing synapse metrics derived from high resolution microscopy assays.</p> <p>Head over to the installation guide to get started; upload guide to share your data; search guide to find data; API documentation for advanced users.</p>"},{"location":"get_started/0-home/#tutorials-on-youtube","title":"Tutorials on YouTube","text":"<p>Explore the tutorials on how to use SynDB on our YouTube playlist.</p>"},{"location":"get_started/0-home/#raise-issues-and-discussions-on-discord","title":"Raise issues and discussions on Discord","text":"<p>Participate in the community on our Discord server.</p>"},{"location":"get_started/1-why_syndb/","title":"Why use SynDB?","text":"<p>In SynDB, there are two perspectives the image data owner and the data scientist. You may skip to these sections if you only care about those perspectives. Feel free to read the entire article.</p>"},{"location":"get_started/1-why_syndb/#image-data-owner","title":"Image data owner","text":"<ul> <li>Data sharing: Others can use your data to teach, increasing the educational value of the data.</li> <li>Citations: Whenever your data is used in a publication, you will be cited, increasing your visibility in the scientific community.</li> </ul>"},{"location":"get_started/1-why_syndb/#data-scientist","title":"Data scientist","text":"<ul> <li>Meta analysis: Compare data across thousands of experiments on the platform to find patterns and insights.</li> <li>Data visualization: Use the data to create visualizations that can be used in publications or presentations.</li> <li>Statistical modelling: Use the data to create models that can be used to predict outcomes in future experiments.</li> </ul>"},{"location":"get_started/2-install/","title":"Installation","text":"<p>The SynDB platform provides several UIs directed towards different user groups. We recommend using the UIs for those getting started with SynDB. For advanced users, the API is the most flexible way to interact with the platform, see the Advanced section.</p>"},{"location":"get_started/2-install/#user-interfaces","title":"User interfaces","text":"<p>The SynDB interfaces are implemented with the Python programming language. To run them you need to have a Python environment.</p> <p>Setup Python environment</p> <p>This requires two things (1) Python interpreter installed in your system, (2) Python environment management for the SynDB packages.</p> <p>There many solutions to both requirements, we recommend using <code>pyenv</code> to solve 1st problem, and pipx for the 2nd. Follow the installation guide for your operating system.</p>"},{"location":"get_started/2-install/#install","title":"Install","text":"pipxpip <pre><code>pipx install syndb-cli[gui]\n</code></pre> <pre><code>pip install syndb-cli[gui]\n</code></pre>"},{"location":"get_started/2-install/#upgrade","title":"Upgrade","text":"<p>To upgrade the SynDB CLI along with the GUI (if installed), run the following command:</p> pipxpip <pre><code>pipx upgrade syndb-cli\n</code></pre> <pre><code>pip install syndb-cli[gui] --upgrade\n</code></pre>"},{"location":"get_started/2-install/#advanced","title":"Advanced","text":""},{"location":"get_started/2-install/#syndb-cli-without-gui","title":"<code>syndb-cli</code> without GUI","text":"pipxpip <pre><code>pipx install syndb-cli\n</code></pre> <pre><code>pip install syndb-cli\n</code></pre>"},{"location":"get_started/2-install/#direct-api-usage","title":"Direct API usage","text":"<p>The API can be accessed through the OpenAPI documentation. For a more tailored approach, you may interact with the API through the <code>syndb-data</code> Python package:</p> poetrypip <pre><code>poetry add syndb-data\n</code></pre> <pre><code>pip install syndb-data\n</code></pre> <p>Alternatively, you may generate your own language bindings using <code>openapi-generator</code>; you will need the SynDB openapi schema.</p>"},{"location":"get_started/3-quick_start/","title":"Quick start","text":""},{"location":"get_started/3-quick_start/#command-line-interface","title":"Command line interface","text":"<p>Following the installation, you may run the SynDB CLI using the following command: <pre><code>syndb\n</code></pre> The internal documentation of the CLI will guide you through the available commands and options. See the upload documentation for uploading with the CLI.</p>"},{"location":"get_started/3-quick_start/#graphical-user-interface","title":"Graphical user interface","text":"<p>After installing the SynDB CLI, which contains the GUI, you may run the GUI using the following command:</p> <pre><code>syndb gui\n</code></pre> <p>The GUI will open in your default web browser, and in case the browser is already open, a new tab will be created. You might also have to refresh the new page to see the GUI.</p> <p>Dark Mode</p> <p>Use the dark reader extension for dark mode in the GUI.</p>"},{"location":"get_started/3-quick_start/#next-steps","title":"Next steps","text":"<ul> <li>Search data</li> <li>Upload data</li> <li>API documentation</li> </ul>"},{"location":"guides/choose_dataset_license/","title":"Choosing a license for your dataset","text":"<p>When sharing microscopy data derived datasets, selecting an appropriate license is crucial for ensuring the proper use and distribution of your work. Different licenses offer varying degrees of freedom and control over your data. Here, we outline some popular licenses, their key features, and considerations to help you choose the right one for your needs.</p>"},{"location":"guides/choose_dataset_license/#considerations-for-choosing-a-license","title":"Considerations for Choosing a License","text":"<ul> <li>Intended Use: Determine whether you want your data to be used freely or with certain restrictions, such as non-commercial use only.</li> <li>Credit and Attribution: Decide if you want to receive credit for your work and if it\u2019s important for you to see how others are using your data.</li> <li>Derivative Works: Consider whether you want derivative works to be allowed and if they should be shared under the same terms.</li> <li>Commercial Use: Reflect on whether you want to permit commercial use of your data. Your institution may have specific policies regarding commercial use.</li> </ul>"},{"location":"guides/choose_dataset_license/#licenses","title":"Licenses","text":"<p>The following are some common licenses used for sharing data on the web, which we also use on the SynDB platform.</p> <p>Use ODC over CC</p> <p>We recommend the ODC licenses for datasets on SynDB. You are free to use Creative Commons licenses as well, just note that they are not designed for data. The default license for SynDB is ODC-BY.</p>"},{"location":"guides/choose_dataset_license/#open-data-commons-odc-licenses","title":"Open Data Commons (ODC) Licenses","text":"<p>Open Data Commons (ODC) licenses are specifically tailored for datasets and databases, focusing on maximizing accessibility and proper attribution in data sharing.</p>"},{"location":"guides/choose_dataset_license/#pddl-public-domain-dedication-and-license","title":"PDDL (Public Domain Dedication and License)","text":"<p>Places the dataset in the public domain, allowing unrestricted use and maximizing openness and usability.</p>"},{"location":"guides/choose_dataset_license/#odc-by-attribution-license","title":"ODC-BY (Attribution License)","text":"<p>Allows use with proper credit to the original creator, ensuring acknowledgment while enabling broad use.</p>"},{"location":"guides/choose_dataset_license/#odc-odbl-open-database-license","title":"ODC-ODbL (Open Database License)","text":"<p>Permits sharing, modifying, and using the dataset with attribution and requires derivative databases to be shared under the same license, promoting open access and collaborative improvement while keeping derivative databases equally accessible.</p>"},{"location":"guides/choose_dataset_license/#creative-commons-cc-licenses","title":"Creative Commons (CC) Licenses","text":"<p>Creative Commons (CC) licenses are versatile and well-suited for a wide range of creative works, including datasets</p>"},{"location":"guides/choose_dataset_license/#cc0-public-domain-dedication","title":"CC0 (Public Domain Dedication)","text":"<p>Allows the use of the dataset without any restrictions, making it ideal for maximizing usability and dissemination.</p>"},{"location":"guides/choose_dataset_license/#cc-by-attribution","title":"CC BY (Attribution)","text":"<p>Allows users to use the dataset as long as they provide appropriate credit to the original creator, ensuring wide use while acknowledging the creator's work.</p>"},{"location":"guides/choose_dataset_license/#cc-by-sa-attribution-sharealike","title":"CC BY-SA (Attribution-ShareAlike)","text":"<p>Permits use of the dataset with appropriate credit and requires sharing derivative works under the same license, keeping derivative works open and shareable under the same terms.</p>"},{"location":"guides/choose_dataset_license/#cc-by-nc-attribution-noncommercial","title":"CC BY-NC (Attribution-NonCommercial)","text":"<p>Allows use for non-commercial purposes with proper credit, restricting use to non-commercial purposes while still enabling academic and research use.</p>"},{"location":"guides/choose_dataset_license/#cc-by-nc-sa-attribution-noncommercial-sharealike","title":"CC BY-NC-SA (Attribution-NonCommercial-ShareAlike)","text":"<p>Permits non-commercial use with appropriate credit and sharing of derivative works under the same license, ensuring non-commercial use and open sharing under the same terms.</p>"},{"location":"guides/choose_dataset_license/#conclusion","title":"Conclusion","text":"<p>Selecting the right license for your microscopy data derived dataset is essential for controlling how your data is used and ensuring it meets your sharing objectives. By considering the options and your specific needs, you can choose a license that balances openness, credit, and control, fostering collaboration and advancement in your field.</p>"},{"location":"guides/contributors_data_structuring/","title":"Metrics structuring for contribution","text":"<p>Prerequisites</p> <p>This article requires that you understand how data is stored on SynDB, we recommend reading through the overview article if you are uncertain.</p> <p>This article is a guide for contributors who wish to upload their data to SynDB. Please don't hesitate to ask for help on the Discord channel if you have any questions; this part can be challenging.</p>"},{"location":"guides/contributors_data_structuring/#data-structuring","title":"Data structuring","text":""},{"location":"guides/contributors_data_structuring/#schema","title":"Schema","text":"<p>Each SynDB table has its own schema, which can be found on our GitHub repository. The schema defines the supported column names and their data types. The data must be structured in a way that is compatible with the schema of the table you are contributing to.</p> <p>The column names and the data stored under them must be in a format that is compatible with the type. You can find the supported column names for each SynDB table in the . You may use the glossary at the end of this article for reference.</p> <p>Nano</p> <p>We use nanometers as the unit for all measurements; includes volume, radius, and distance.</p>"},{"location":"guides/contributors_data_structuring/#sourcing-raw-data","title":"Sourcing raw data","text":"<p>You may upload the sourcing raw data files including meshes or SWL to SynDB. Place the absolute path to the file in your table file. The following are supported:</p> <ul> <li>Meshes in <code>.glb</code> format, column name: <code>mesh_path</code></li> <li>SWC files, <code>.swc</code>, column name: <code>swc_path</code></li> </ul> <p>This list is the main tracker for the supported formats. You may request additional formats on the Discord channel. The SynDB team will review the request and consider adding the new format to the platform.</p>"},{"location":"guides/contributors_data_structuring/#columns","title":"Columns","text":"<p>Most column types are self-explanatory, but some require additional explanation.</p>"},{"location":"guides/contributors_data_structuring/#identifiers-and-relations","title":"Identifiers and relations","text":"<p>The CID column defined in your table can have any unique hashable value, it will be replaced by a UUID when uploaded to SynDB. When uploading a relational dataset, the <code>cid</code> column in the parent will be used to correlate the relations to the children by their <code>parent_id</code>; meaning the hashable value in the parent <code>cid</code> column must match the <code>parent_id</code> in the child. <code>parent_enum</code> can be omitted as the compartments are defined at the tabular level, and will, therefore, be added automatically.</p>"},{"location":"guides/contributors_data_structuring/#example","title":"Example","text":"<p>Notice the <code>parent_id</code> column in the child table, this is the <code>cid</code> of the parent table. The <code>parent_enum</code> column is not present in the child table, as it is defined at the tabular file name.</p>"},{"location":"guides/contributors_data_structuring/#vesiclecsv-child","title":"vesicle.csv, child","text":"cid neurotransmitter voxel_radius distance_to_active_zone minimum_normal_length parent_id centroid_z centroid_x centroid_y 0 glutamate 26.9129 705.2450 23 1 4505.232 1996.224 4953.6 1 glutamate 25.5388 615.0213 23 1 4505.232 1996.224 4953.6 2 glutamate 29.5260 513.0701 23 1 4505.232 1996.224 4953.6 3 glutamate 30.5131 479.9224 23 1 4505.232 1996.224 4953.6 4 glutamate 28.3977 454.8248 23 1 4505.232 1996.224 4953.6 5 glutamate 30.2033 459.7557 23 2 4505.232 1996.224 4953.6 6 glutamate 33.4548 374.8131 23 2 4505.232 1996.224 4953.6 7 glutamate 32.0890 455.9293 23 4 4505.232 1996.224 4953.6"},{"location":"guides/contributors_data_structuring/#axoncsv-parent","title":"axon.csv, parent","text":"voxel_volume mitochondria_count total_mitochondria_volume cid 385668034.56 1 93208043.52 1 1492089016.32 4 412054179.84 2 327740497.92 0 0 4"},{"location":"guides/contributors_data_structuring/#glossary","title":"Glossary","text":"Key Description <code>dataset_id</code> The unique identifier for the dataset, of type <code>uuid</code>. <code>cid</code> The unique identifier for a SynDB unit within the dataset, of type <code>uuid</code>. <code>parent_id</code> The CID of the parent component, of type <code>uuid</code>. <code>parent_enum</code> An integer representing the type or category of the parent component, of type <code>int</code>. <code>polarity</code> The polarity of the neuron, of type <code>ascii</code>. <code>voxel_volume</code> The volume of the voxel, of type <code>double</code>. <code>voxel_radius</code> The radius of the voxel, of type <code>double</code>. <code>s3_mesh_location</code> The location of the mesh in S3 storage, of type <code>smallint</code>. <code>mesh_volume</code> The volume of the mesh, of type <code>double</code>. <code>mesh_surface_area</code> The surface area of the mesh, of type <code>double</code>. <code>mesh_area_volume_ratio</code> The ratio of the surface area to the volume of the mesh, of type <code>double</code>. <code>mesh_sphericity</code> The sphericity of the mesh, of type <code>double</code>. <code>centroid_z</code> The z-coordinate of the centroid, of type <code>double</code>. <code>centroid_x</code> The x-coordinate of the centroid, of type <code>double</code>. <code>centroid_y</code> The y-coordinate of the centroid, of type <code>double</code>. <code>s3_swb_location</code> The location of the SWB in S3 storage, of type <code>smallint</code>. <code>terminal_count</code> The count of terminals, of type <code>int</code>. <code>mitochondria_count</code> The count of mitochondria, of type <code>int</code>. <code>total_mitochondria_volume</code> The total volume of mitochondria, of type <code>double</code>. <code>neuron_id</code> The unique identifier for the associated neuron, of type <code>uuid</code>. <code>vesicle_count</code> The count of vesicles, of type <code>int</code>. <code>total_vesicle_volume</code> The total volume of vesicles, of type <code>double</code>. <code>forms_synapse_with</code> The unique identifier of the synapse that the component forms with, of type <code>uuid</code>. <code>connection_score</code> The score representing the strength or quality of the connection, of type <code>double</code>. <code>cleft_score</code> The score for the synaptic cleft, of type <code>int</code>. <code>GABA</code> The concentration or presence of GABA neurotransmitter, of type <code>double</code>. <code>acetylcholine</code> The concentration or presence of acetylcholine neurotransmitter, of type <code>double</code>. <code>glutamate</code> The concentration or presence of glutamate neurotransmitter, of type <code>double</code>. <code>octopamine</code> The concentration or presence of octopamine neurotransmitter, of type <code>double</code>. <code>serine</code> The concentration or presence of serine neurotransmitter, of type <code>double</code>. <code>dopamine</code> The concentration or presence of dopamine neurotransmitter, of type <code>double</code>. <code>cave_id</code> The identifier of the cave structure, of type <code>int</code>. <code>pre_id</code> The unique identifier of the pre-synaptic component, of type <code>uuid</code>. <code>post_id</code> The unique identifier of the post-synaptic component, of type <code>uuid</code>. <code>dendritic_spine_count</code> The count of dendritic spines, of type <code>int</code>. <code>neurotransmitter</code> The type of neurotransmitter present in a vesicle, of type <code>ascii</code>. <code>distance_to_active_zone</code> The distance from the vesicle to the active zone, of type <code>double</code>. <code>minimum_normal_length</code> The minimum normal length, of type <code>int</code>. <code>ribosome_count</code> The count of ribosomes within the endoplasmic reticulum, of type <code>int</code>."}]}